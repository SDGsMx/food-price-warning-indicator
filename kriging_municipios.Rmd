---
title: "R Notebook"
output: html_notebook
---

 
```{r, message=FALSE, warning=FALSE, comment=NA, results='hide'}
library(tidyverse)
library(lubridate)
library(stringr)
```

```{r, results='hide', message=FALSE}
tipo_cambio <-read_csv("data/tipo_de_cambio.csv") %>%
  mutate(fecha = dmy(fecha)) %>%
  mutate(año = year(fecha))  %>%
  mutate(mes = month(fecha)) %>%
  select(año,mes,tipo_cambio)
```


```{r, results='hide', message=FALSE}
internacional <- read_csv("data/precio_internacional_dolares.csv") %>% 
  separate(Month, c("mes", "año"), " ")  %>%
  mutate(año = as.numeric(año))  %>%
  filter(año>2000) %>%
  mutate(mes = match(mes,month.abb))  %>%
  mutate(fecha = make_datetime(year=año, month=mes, day=1)) %>%
  mutate(fecha= ymd(fecha)) %>%
  rename(int_price = Price) %>% 
  left_join(tipo_cambio) %>%
  # Obtenemos el precio por kilogramo (De tonelada) por el tipo de cambio
  mutate(int_price = (int_price*tipo_cambio)/1000) %>% 
  select(fecha,año,mes,int_price) 
```


# Precios nacionales promedio por estado:

```{r, results='hide', message=FALSE, comment=NA, warning=FALSE}
nacional <- read_csv("data/precios_granos_semanales.csv")
nacional <- select(nacional,producto,precio_min,fecha,edo_destino,obs) %>% 
  mutate(fecha=dmy(fecha)) %>% # tipo de fecha
  mutate(precio_min = ifelse(precio_min > 8, NA, precio_min)) # identificamos un outlier
```


```{r, message=FALSE, warning=FALSE}
estados_dic <- read_csv("data/estados_dic.csv") %>%
  rename(edo_destino=NOM_ENT) %>% 
  mutate(edo_destino = str_to_lower(edo_destino)) %>%
  mutate(CVE_ENT = str_pad(CVE_ENT, 2, pad = "0"))
```


```{r, message=FALSE, warning=FALSE}
maiz_nacional <- read_csv("data/precios_granos_semanales.csv") %>%
  select(producto,fecha,edo_destino,precio_min,obs) %>% 
  #definimos variable de fecha
  mutate(fecha=dmy(fecha)) %>%
  #filtramos el outlier
  filter(precio_min < 15) %>%  
  arrange(fecha) %>%
  mutate(mes = month(fecha)) %>% 
  mutate(año = year(fecha)) %>% 
  mutate(fecha = make_datetime(year=año,month=mes,1)) %>% 
  mutate(fecha = ymd (fecha)) %>%
  left_join(estados_dic,by = "edo_destino") %>%
    mutate(CVE_ENT = ifelse(edo_destino== "michoacán", "16", 
                          ifelse(edo_destino== "veracruz","30",
                                 ifelse(edo_destino=="df","09",
                                        ifelse(edo_destino=="coahuila","05",CVE_ENT))))) 
```


```{r}
nacional <- maiz_nacional %>%
  group_by(fecha,año,mes) %>% 
  summarise(precio_promedio = mean(precio_min, na.rm = TRUE)) %>% 
  left_join(internacional,by = c("fecha", "año", "mes")) 
nacional_2 <- nacional %>%
  ungroup() %>% as_data_frame() %>%
  select(fecha, precio_promedio, int_price) 
colnames(nacional_2) <- c("Fecha","Promedio nacional", "Precio internacional")
nacional_2 <- nacional_2 %>% 
  gather(key = Precios, value = Precio, -Fecha) %>%
  filter(!is.na(Precio))
ggplot(nacional_2) + 
  geom_line(aes(x = Fecha, y = Precio, color = Precios)) + 
  scale_x_date(date_breaks = "6 months", date_labels = "%b %y") + 
  theme(legend.position="bottom", axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
# Obtener una base tipo panel para cada estado del precio por mes del maiz blanco
semantic <- maiz_nacional %>%
  ungroup() %>% as.data.frame() %>%
  select(CVE_ENT,fecha,precio_min) %>%
  group_by(fecha,CVE_ENT) %>%
  summarise(precio_promedio = mean(precio_min,na.rm=TRUE)) %>%
  spread(key = CVE_ENT, value = precio_promedio) %>%
  left_join(nacional%>%ungroup()%>%select(fecha,int_price), estatal, by = c("fecha")) %>%
  arrange(fecha) %>%
  filter(!is.na(int_price)) %>%
  filter(fecha >= ymd("2005-05-01")) %>%
  select(fecha,`01`,`03`:`11`,`13`:`26`,`28`:int_price) %>%
  ungroup %>% as.data.frame() %>%
  gather(key = CVE_ENT, value = precio_promedio, -fecha, -int_price) %>%
  mutate(CVE_ENT = as.integer(CVE_ENT))
```


```{r, message=FALSE, warning=FALSE}
central_abastos <- read_csv(file = "data/central_abastos_test.csv")
alerta_estados <- read_csv(file = "data/semantic_alerta_estados.csv")
precios_semanales <- read_csv(file = "data/precios_granos_semanales.csv")
```


```{r}
semantic_nacional <- semantic %>%
  filter(complete.cases(int_price)) %>% # filtrar dato faltante del precio internacional
  ungroup() %>%
  select(-año, -mes, -precio_promedio) %>%
  gather(key = Entidad, value = Precio, -fecha, -int_price)
```


```{r, message=FALSE, warning=FALSE}
library(R2jags)
library(gridExtra)
```


El objetivo planteado es hacer un modelo dinámico de segundo orden:

Sea $i$ el tiempo en el que se observa la medición del precio del maíz y $j$ el estado correspondiente a la observación:

Para $t=1,2,\ldots$ se tiene que
$$
\begin{aligned}
\mu_{ij} &= \alpha_{i(j)} + \beta_j + \gamma_i f_i, \quad p_{ij} \sim N(\mu_{ij},\tau_{p}), \\
\eta_{i(j)} &= \alpha_{i-1(j)}, \quad \alpha_{i(j)} \sim N(\eta_{i(j)},\tau_\alpha).
\end{aligned}
$$

Las distribuciones iniciales son:
$$
\begin{aligned}
\tau_p &= 1/\sigma_p^2, \\
\sigma_p &\sim \mbox{Gamma}(1,0.01), \\
\beta_j,\gamma_i &\sim N(0,0.001), \\
\tau_\alpha &= 1/\sigma_\alpha^2,\\
\sigma_\alpha &\sim \mbox{Gamma}(1,0.01)
\end{aligned}
$$


Parámetros iniciales:
```{r}
n <- length(unique(semantic$fecha))
fecha_num <- 1:n
fn <- data.frame(fn=fecha_num, fecha=unique(semantic$fecha))
semantic <- semantic %>% left_join(fn, by = "fecha")
m <- length(unique(semantic$CVE_ENT))
entidad_recode <- data.frame(CVE_ENT=unique(semantic$CVE_ENT),rec = 1:m)
semantic <- semantic %>% left_join(entidad_recode, by = "CVE_ENT")
entidad <- semantic$rec
precio <- semantic$precio_promedio
pint <- semantic$int_price
fn <- semantic$fn
data <- list("n"=n, "m"=m, "j"=entidad, "p"=precio, "f"=pint, 
             "obs"=length(precio), "fn"=fn)
inits <- function(){list(alpha=rep(0,n),tau.p=1,tau.a=1,yf1=rep(0,length(precio)),
                         beta=rep(0,m),gamma=rep(1,n))}
parameters <- c('alpha','tau.p','tau.a','beta','gamma','yf1')
```

```{r}
modelo.txt <-
'
model
{
  #Likelihood
  # Space eq
  for(i in 1:obs){
    p[i] ~ dnorm(mu[i],tau.p)
    mu[i] <- alpha[fn[i]] + beta[j[i]] + gamma[fn[i]] * f[fn[i]]
  }
  #state eq
  for(i in 2:n){
    alpha[i] ~ dnorm(mu.a[i],tau.a)
    mu.a[i] <- mu[j[i-1]]
  }
  #priors
  alpha[1] ~ dnorm(0,0.001)
  tau.p ~ dgamma(0.001,0.001)
  tau.a ~ dgamma(0.001,0.001)
  for(i in 1:n){
    gamma[i] ~ dnorm(0,0.001)
  }
  for(k in 1:m){
    beta[k] ~ dnorm(0,0.001)
  }
  # prediccion 1
  for(i in 1:obs){
    yf1[i] ~ dnorm(mu[i],tau.p)
  }
}
'
cat(modelo.txt, file = 'modelo.bugs')
```



```{r,warning=FALSE,message=FALSE}
jags_fit <- jags(
  model.file = "modelo.bugs",    # modelo de JAGS
  inits = inits,   # valores iniciales
  data = data,    # lista con los datos
  parameters.to.save = parameters,  # parámetros por guardar
  n.chains = 2,   # número de cadenas
  n.iter = 1000,    # número de pasos
  n.burnin = 100,   # calentamiento de la cadena
  n.thin = 1
)
```


Ahora vamos a evaluar los resultados. Lo primero que tenemos que hacer es revisar la convergencia de la cadena. Para esto vemos la siguiente gráfica para la devianza:


```{r,echo=FALSE,cache=TRUE}
analisis_estimacion <- function(z,title){
  g1 <- ggplot(data.frame(est=1:length(z),z=z),aes(x=est,y=z))+
    geom_line(color='hotpink') 
  g2 <- ggplot(data.frame(est=1:length(z),z=z),aes(x=est,
              y=cumsum(z)/(1:length(z))))+
    geom_line(color='hotpink') + ylab('')
  g3 <- ggplot(data.frame(z),aes(x=z))+
  geom_histogram(aes(y=..density..),colour = 'darkviolet', fill = 'lightpink',bins=30) +
    geom_density() +
    geom_vline(xintercept = c(quantile(z,0.025),quantile(z,0.975),mean(z)),
               size = 1.2,color = c('hotpink4','hotpink4','deeppink'))
  lag <- (1:round(+10*log(length(z),10)))-1
  bacf <- acf(z, plot = FALSE)
  bacfdf <- data.frame(lag=bacf$lag,acf=bacf$acf)
  ciline <- qnorm((1 - 0.95)/2)/sqrt(length(z))
  g4 <- ggplot(data = bacfdf, mapping = aes(x = lag, y = acf)) +
        geom_hline(aes(yintercept = 0)) +
        geom_segment(mapping = aes(xend = lag, yend = 0),color='navyblue') +
          geom_hline(yintercept = -ciline, color = "mediumorchid",size = 0.2) +
          geom_hline(yintercept = ciline, color = "mediumorchid", size = 0.2) +
          theme(title=element_text(size=20))
  grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2,top=title)
}
```


```{r,echo=FALSE}
out <- jags_fit$BUGSoutput$sims.list
z <- out$deviance
analisis_estimacion(z,'deviance')
```


Se puede ver que la devianza es aproximadamente 3703.

El DIC es 
```{r}
jags_fit$BUGSoutput$DIC
```



Analicemos los precios ajustados para la entidad 1:

```{r,echo=FALSE,fig.width=5,fig.height=3}
out.sum <- jags_fit$BUGSoutput$summary

#Predictions
out.yf<-out.sum[grep("yf1",rownames(out.sum)),]
media <- out.yf[,1]; inf <- out.yf[,3]; sup <- out.yf[,7];
semantic_2 <- semantic %>% 
  select(fn,rec,precio_promedio) %>%
  bind_cols(data.frame(media,inf,sup)) %>%
  filter(rec == 1)

ggplot(semantic_2) +
  geom_point(aes(x=fn, y = precio_promedio), color = "grey80", size = 2) + 
  geom_line(aes(x=fn, y = media), color = "navyblue", linetype = 1) +
  geom_line(aes(x=fn, y = inf), color = "navyblue", linetype = 2) +
  geom_line(aes(x=fn, y = sup), color = "navyblue", linetype = 2)
```
